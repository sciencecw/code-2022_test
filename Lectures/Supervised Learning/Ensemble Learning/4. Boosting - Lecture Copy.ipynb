{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7233730b",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "\n",
    "Another common ensemble learning approach is to compile a large collection of weak learners.\n",
    "\n",
    "## What we will accomplish\n",
    "\n",
    "In this notebook we will:\n",
    "- Introduce the concepts of:\n",
    "    - Weak learners and \n",
    "    - Strong learners and\n",
    "- Give a description of boosting algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e2cfb7",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    "Boosting is a very powerful algorithm and is one of the techniques utilized in a number of winning data science competition entries. The theory behind the algorithm is based on the concepts of <i>weak learners</i> and <i>strong learners</i> from the subfield in Statistical Learning on <i>PAC learnability</i>, here PAC stands for <a href=\"https://en.wikipedia.org/wiki/Probably_approximately_correct_learning\">Probably Approximately Correct</a>. We touch lightly on the theory now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22ef0f8",
   "metadata": {},
   "source": [
    "### Weak learner vs strong learner\n",
    "\n",
    "A statistical learning algorithm is referred to as <i>weak learner</i> if it does slightly better than random guessing.\n",
    "\n",
    "A statistical learning algorithm is called a <i>strong learner</i> if it can be made arbitrarily close to the true relationship.\n",
    "\n",
    "Making a weak learner is much easier than producing a strong learner in general, however, it has been shown that if a problem is weak learnable (meaning that a weak learner exists) then it is stong learnable (meaning that a strong learner exists). The fact that one exists led to the creation of algorithms and techniques to produce a strong learner. This is where boosting comes into play. \n",
    "\n",
    "In practice, a common weak learner algorithm is a <i>decision stump</i>, which is a decision tree with a single layer.\n",
    "\n",
    "#### Together we are strong\n",
    "\n",
    "The idea for boosting is to take an ensemble of weak learners and with their power combined produce a strong learner.\n",
    "\n",
    "\n",
    "##### Regression or classification\n",
    "\n",
    "Boosting can be used for regression or classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c4f5ab",
   "metadata": {},
   "source": [
    "### Two specific boosting algorithms\n",
    "\n",
    "We will cover two boosting algorithms:\n",
    "1. Adaptive Boosting and\n",
    "2. Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca96712",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b40a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
