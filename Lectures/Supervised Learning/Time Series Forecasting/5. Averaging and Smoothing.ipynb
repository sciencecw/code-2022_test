{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9f88af",
   "metadata": {},
   "source": [
    "# Averaging and Smoothing\n",
    "\n",
    "The first type of model we will investigate uses some kind of average of the value at previous time steps to predict the next time step.\n",
    "\n",
    "## What we will accomplish\n",
    "\n",
    "In this notebook we will:\n",
    "- Introduce the concept behind averaging or smoothing,\n",
    "- Define an average model,\n",
    "- Build upon that with a weighted average model,\n",
    "- Learn about simple exponential smoothing,\n",
    "- Extend that to double exponential smoothing and\n",
    "- End with triple exponential smoothing or the Holt Winters model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe39a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from seaborn import set_style\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a1b1fa",
   "metadata": {},
   "source": [
    "## What is an averaging/smoothing forecast\n",
    "\n",
    "An averaging or smoothing forecast is one in which we take an average of some collection of previous values to predict the future value.\n",
    "\n",
    "### Moving average forecast\n",
    "\n",
    "For example,\n",
    "\n",
    "$$\n",
    "y_{t+1} = \\frac{1}{3}\\left(y_t + y_{t-1} + y_{t-2} \\right) + \\epsilon_t\n",
    "$$\n",
    "\n",
    "is an averaging forecast. Specifically this is known as a <i>moving average forecast</i> because you shift the points over which you average as $t$ increases.\n",
    "\n",
    "In general the moving average forecast with window size $k$ is:\n",
    "\n",
    "$$\n",
    "y_{t+1} = \\left\\lbrace \\begin{array}{l c c} \\frac{1}{k} \\sum_{i=0}^{k-1} y_{t-i} + \\epsilon_t & \\text{for} & t \\leq n-1 \\\\\n",
    "\\frac{1}{k} \\sum_{i=0}^{k-1} y_{n-i} + \\epsilon_t & \\text{for} & t \\geq n \\end{array} \\right\\rbrace\n",
    "$$\n",
    "\n",
    "We can implement this on the Google stock data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772b048e",
   "metadata": {},
   "outputs": [],
   "source": [
    "goog = pd.read_csv(\"../../../Data/google_stock.csv\", parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bb1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "goog_train = goog.iloc[:-14].copy()\n",
    "goog_test = goog.iloc[-14:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996aae97",
   "metadata": {},
   "source": [
    "`pandas` has nice functionality for computing moving averages called `rolling`, <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html\">https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1136906",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To use rolling\n",
    "## specify the column you want the moving average of\n",
    "## give the window size as the argument\n",
    "## then give what you want the moving statistic of, we want the mean()\n",
    "## Finally set the argument closed='left' to ensure that y_{t+1} is the average\n",
    "## of the previous k values.\n",
    "pd.DataFrame({'closing_price':goog_train.closing_price,\n",
    "                  'moving_avg':})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305918f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "\n",
    "plt.plot(goog_train.date[-75:], \n",
    "         goog_train.closing_price[-75:],\n",
    "         'b',\n",
    "         label=\"Training Data\")\n",
    "\n",
    "plt.plot(goog_train.date[-75:], \n",
    "         goog_train.closing_price.rolling(3, closed=\"left\").mean()[-75:],\n",
    "         'g--',\n",
    "         label=\"Training Rolling Average\")\n",
    "\n",
    "plt.plot(goog_test.date, \n",
    "         goog_test.closing_price,\n",
    "         'r',\n",
    "         label=\"Test Data\")\n",
    "\n",
    "plt.plot(goog_test.date, \n",
    "         goog_train.closing_price[-3:].mean()*np.ones(14),\n",
    "         'r--o',\n",
    "         label=\"Rolling Average Prediction\")\n",
    "\n",
    "plt.xlabel(\"Date\", fontsize=18)\n",
    "plt.ylabel(\"Closing Price\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14, loc=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3b21f8",
   "metadata": {},
   "source": [
    "As you may have noticed, the moving average tends to lag behind the actual data. This is a weakness of the model.\n",
    "\n",
    "Moving averages can be used for more than just making forecasts. We can also use them to look for trends or patterns in the data set. This can be accomplished by changing the window size.\n",
    "\n",
    "For example, below as we increase the window size we start to reveal the increasing trend of the data set. While we could have identified this trend without the moving average, there are some noisier data sets in which patterns are more difficult to identify and the moving average can help us find hard to see seasonality or trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6007d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(4, 1, figsize=(20,20), sharex=True, sharey=True)\n",
    "\n",
    "ax[0].plot(goog.date, \n",
    "           goog.closing_price,\n",
    "           alpha=.6,\n",
    "           label=\"Data\")\n",
    "ax[0].plot(goog.date, \n",
    "           goog.closing_price.rolling(10, closed='left').mean(),\n",
    "           '--',\n",
    "           linewidth=1.5,\n",
    "           label=\"Moving Average\")\n",
    "\n",
    "ax[0].legend(fontsize=16)\n",
    "ax[0].set_title(\"Window Size = 10\", fontsize=16)\n",
    "\n",
    "ax[1].plot(goog.date, \n",
    "           goog.closing_price,\n",
    "           alpha=.6,\n",
    "           label=\"Data\")\n",
    "ax[1].plot(goog.date, \n",
    "           goog.closing_price.rolling(100, closed='left').mean(),\n",
    "           '--',\n",
    "           linewidth=1.5,\n",
    "           label=\"Moving Average\")\n",
    "ax[1].set_title(\"Window Size = 100\", fontsize=16)\n",
    "\n",
    "\n",
    "ax[2].plot(goog.date, \n",
    "           goog.closing_price,\n",
    "           alpha=.6,\n",
    "           label=\"Data\")\n",
    "ax[2].plot(goog.date, \n",
    "           goog.closing_price.rolling(500, closed='left').mean(),\n",
    "           '--',\n",
    "           linewidth=1.5,\n",
    "           label=\"Moving Average\")\n",
    "ax[2].set_title(\"Window Size = 500\", fontsize=16)\n",
    "\n",
    "\n",
    "ax[3].plot(goog.date, \n",
    "           goog.closing_price,\n",
    "           alpha=.6,\n",
    "           label=\"Data\")\n",
    "ax[3].plot(goog.date, \n",
    "           goog.closing_price.rolling(1000, closed='left').mean(),\n",
    "           '--',\n",
    "           linewidth=1.5,\n",
    "           label=\"Moving Average\")\n",
    "ax[3].set_title(\"Window Size = 1000\", fontsize=16)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plt.xlabel(\"Date\", fontsize=18)\n",
    "# plt.ylabel(\"Closing Price\", fontsize=18)\n",
    "\n",
    "# plt.xticks(fontsize=14)\n",
    "# plt.yticks(fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca975d0",
   "metadata": {},
   "source": [
    "### More general weighted average forecasts\n",
    "\n",
    "To this point we have only considered average forecasts in which each previous time point considered has been given equal weight. You can more generally apply disproportionate weighting, for example if you wanted to give more weight to the recent observations.\n",
    "\n",
    "As an example we will visualize the following weighted moving average forecast on the Google data:\n",
    "\n",
    "$$\n",
    "y_{t} = \\left\\lbrace \\begin{array}{l c c} \\frac{2}{3}y_{t-1} + \\frac{1}{6}y_{t-2} + \\frac{1}{6} y_{t-3} + \\epsilon_t & \\text{for} & t \\leq n-1 \\\\\n",
    "\\frac{2}{3}y_{n-1} + \\frac{1}{6}y_{n-2} + \\frac{1}{6} y_{n-3} + \\epsilon_t & \\text{for} & t \\geq n \\end{array} \\right\\rbrace\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91809637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_avg(t):\n",
    "    return \n",
    "\n",
    "goog_train_fit = []\n",
    "\n",
    "for i in range(3,len(goog_train)):\n",
    "    goog_train_fit.append(weight_avg(i))\n",
    "        \n",
    "        \n",
    "pred = weight_avg(len(goog_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a0f6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "\n",
    "plt.plot(goog_train.date[-75:], \n",
    "         goog_train.closing_price[-75:],\n",
    "         'b',\n",
    "         label=\"Training Data\")\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(goog_train.date[-75:], \n",
    "         goog_train_fit[-75:],\n",
    "         'g--',\n",
    "         label=\"Training Weighted Rolling Average\")\n",
    "\n",
    "plt.plot(goog_test.date, \n",
    "         goog_test.closing_price,\n",
    "         'r',\n",
    "         label=\"Test Data\")\n",
    "\n",
    "plt.plot(goog_test.date, \n",
    "         pred*np.ones(14),\n",
    "         'r--o',\n",
    "         label=\"Weighted Rolling Average Prediction\")\n",
    "\n",
    "plt.xlabel(\"Date\", fontsize=18)\n",
    "plt.ylabel(\"Closing Price\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14, loc=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5855cc2",
   "metadata": {},
   "source": [
    "#### Underlying model\n",
    "\n",
    "An underlying statistical model for these types of forecasts can be established. Let $\\left\\lbrace \\epsilon_t \\right\\rbrace$ be a white noise sequence. Then a moving average stochastic process of order $q$ (MA($q$)) is given by: $y_t = \\beta_0 \\epsilon_t + \\beta_1 \\epsilon_{t-1} + \\dots + \\beta_q \\epsilon_{t-q}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf889971",
   "metadata": {},
   "source": [
    "## Exponential smoothing\n",
    "\n",
    "We will introduce three exponential smoothing forecasts.\n",
    "\n",
    "In order to define these forecasts it is useful to reintroduce the <i>hat</i> notation we have used in the past. Let $\\hat{y}_t$ denote the forecast according to the model at time $t$.\n",
    "\n",
    "### Simple exponential smoothing\n",
    "\n",
    "First we will define simple exponential smoothing:\n",
    "\n",
    "$$\n",
    "\\hat{y}_{t+1} = \\left\\lbrace \\begin{array}{l c c}\\alpha y_t + (1-\\alpha) \\hat{y}_t & \\text{for} & t\\leq n \\\\\n",
    "                                               \\alpha y_n + (1-\\alpha) \\hat{y}_n & \\text{for} & t > n \\end{array}\\right\\rbrace, \n",
    "$$\n",
    "\n",
    "where $\\alpha \\in [0,1]$ is a hyperparameter that you can select by hand or through some kind of algorithm.\n",
    "\n",
    "There are two ways that it may be helpful to think about this model.\n",
    "\n",
    "##### 1. An adjustment of the naive forecast\n",
    "\n",
    "With a little rearrangement you can turn simple exponential smoothing into:\n",
    "\n",
    "$$\n",
    "\\hat{y}_{t+1} = \\hat{y}_t + \\alpha \\left( y_t - \\hat{y}_t \\right) = \\hat{y}_t + \\alpha e_t,\n",
    "$$\n",
    "\n",
    "where we can think of $e_t$ as an \"error\" term.\n",
    "\n",
    "##### 2. A weighted average that we can \"optimize\"\n",
    "\n",
    "When it is written out all the way the simple exponential smoothing is:\n",
    "\n",
    "$$\n",
    "\\hat{y}_{t+1} = \\alpha \\left[y_t +(1-\\alpha) y_{t-1} + (1-\\alpha)^2 y_{t-2} + \\dots + (1-\\alpha)^{t-1} y_1\\right].\n",
    "$$\n",
    "\n",
    "This is a weighted sum including all prior information for which we can find the \"optimal\" value of $\\alpha$, where here \"optimal\" may mean different things depending on your end goal.\n",
    "\n",
    "By contrast, if we attempted to find unique weights for each time step finding the ones that provide the \"best\" model for our data may be difficult.\n",
    "\n",
    "#### Simple exponential smoothing in python\n",
    "\n",
    "We can implement the simple exponential smoothing model in python with the `statsmodels` package, <a href=\"https://www.statsmodels.org/stable/index.html\">https://www.statsmodels.org/stable/index.html</a>. First we will check that we have this package installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af669f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing statsmodels to check that we have it installed\n",
    "import statsmodels as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599601b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## printing the statsmodels version\n",
    "## I had version 0.13.1 when I wrote this notebook\n",
    "print(sm.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e102fe0e",
   "metadata": {},
   "source": [
    "If needed, installation instructions for pip and conda can be found here <a href=\"https://www.statsmodels.org/stable/install.html\">https://www.statsmodels.org/stable/install.html</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c112b0bd",
   "metadata": {},
   "source": [
    "Simple exponential smoothing can be implemented with the `SimpleExpSmoothing` model type in `statsmodels`, <a href=\"https://www.statsmodels.org/devel/generated/statsmodels.tsa.holtwinters.ExponentialSmoothing.html#statsmodels.tsa.holtwinters.ExponentialSmoothing\">https://www.statsmodels.org/devel/generated/statsmodels.tsa.holtwinters.ExponentialSmoothing.html#statsmodels.tsa.holtwinters.ExponentialSmoothing</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7758e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the model from statsmodels\n",
    "from statsmodels.tsa.api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a242e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To fit a SimpleExpSmoothing model you\n",
    "## First call SimpleExpSmoothing with the training data\n",
    "## then .fit\n",
    "## with smoothing_level, this is alpha\n",
    "## and optimized=False, if this is True alpha is found using the method of maximum likelihood\n",
    "simp_exp_smooth = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a93af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "\n",
    "plt.plot(goog_train.date[-75:], \n",
    "         goog_train.closing_price[-75:],\n",
    "         'b',\n",
    "         label=\"Training Data\")\n",
    "\n",
    "\n",
    "## We can get the fitted values with fittedvalues\n",
    "plt.plot(goog_train.date[-75:], \n",
    "         simp_exp_smooth.fittedvalues[-75:],\n",
    "         'g--',\n",
    "         label=\"Simple Exponential Smoothing Fit\")\n",
    "\n",
    "plt.plot(goog_test.date, \n",
    "         goog_test.closing_price,\n",
    "         'r',\n",
    "         label=\"Test Data\")\n",
    "\n",
    "## We can get the forecast with .forecast(h)\n",
    "plt.plot(goog_test.date, \n",
    "         simp_exp_smooth.forecast(14),\n",
    "         'r--o',\n",
    "         label=\"Weighted Rolling Average Prediction\")\n",
    "\n",
    "plt.xlabel(\"Date\", fontsize=18)\n",
    "plt.ylabel(\"Closing Price\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14, loc=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef5392d",
   "metadata": {},
   "source": [
    "Here we could use cross-validation or a validation set to find the \"best\" $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90a982c",
   "metadata": {},
   "source": [
    "#### Underlying model\n",
    "\n",
    "An underlying model for the time series that would be appropriate for simple exponential smoothing can be described. Let $\\left\\lbrace \\epsilon_t \\right\\rbrace$ be a white noise sequence. Then the model is given by $y_t = \\mu + \\alpha \\sum_{j<t} \\epsilon_j + \\epsilon_t$ for $\\mu \\in \\mathbb{R}$ and $\\alpha \\in [0,1]$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6139c087",
   "metadata": {},
   "source": [
    "### Double exponential smoothing\n",
    "\n",
    "Simple exponential smoothing does not deal well with time series that exhibit a trend. An expansion built to handle trends is <i>double exponential smoothing</i>. This model is \"double\" exponential smoothing because we literally do two times the exponential smoothing as simple exponential smoothing:\n",
    "\n",
    "\n",
    "$$\n",
    "\\hat{y}_{t} = \\left\\lbrace \\begin{array}{l c c} s_{t-1} + b_{t-1} & \\text{for} & 1<t\\leq n \\\\\n",
    "                                                s_n + (t-n)b_{n}& \\text{for} & t > n \\end{array}\\right\\rbrace, \n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "s_{t+1} = \\alpha y_t + (1-\\alpha) (s_{t-1} + b_{t-1}), \\ s_1 = y_1, \n",
    "$$\n",
    "\n",
    "$$\n",
    "b_{t+1} = \\beta (s_t - s_{t-1}) + (1-\\beta) b_{t-1}, \\ b_1 = y_2 - y_1 \\text{ and}\n",
    "$$\n",
    "\n",
    "$\\alpha \\in [0,1]$ and $\\beta \\in [0,1]$ are hyperparameters that we can select by hand or though an optimization process.\n",
    "\n",
    "The first exponential smoothing is applied much like simple exponential smoothing to the observed values of the time series and the second exponential smoothing is applied to the \"trend\" which is approximated with a series of first differences ($y_{t} - y_{t-1}$ or $s_t - s_{t-1}$).\n",
    "\n",
    "#### Double exponential smoothing in python\n",
    "\n",
    "We can implement this in python with `statsmodel`'s `Holt` model object, <a href=\"https://www.statsmodels.org/devel/generated/statsmodels.tsa.holtwinters.Holt.html\">https://www.statsmodels.org/devel/generated/statsmodels.tsa.holtwinters.Holt.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import Holt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4652195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here in addition to setting a smoothing_level\n",
    "## we also set a smoothing_trend, which is the value of beta\n",
    "## again we set optimized = False, unless we'd rather choose alpha and beta through\n",
    "## maximum likelihood estimation\n",
    "exp_smooth = Holt(goog_train.closing_price.values).fit(smoothing_level=0.6, \n",
    "                                          smoothing_trend=0.6,\n",
    "                                          optimized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c82998",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "\n",
    "plt.plot(goog_train.date[-75:], \n",
    "         goog_train.closing_price[-75:],\n",
    "         'b',\n",
    "         label=\"Training Data\")\n",
    "\n",
    "\n",
    "## We can get the fitted values with fittedvalues\n",
    "plt.plot(goog_train.date[-75:], \n",
    "         exp_smooth.fittedvalues[-75:],\n",
    "         'g--',\n",
    "         label=\"Double Exponential Smoothing Fit\")\n",
    "\n",
    "plt.plot(goog_test.date, \n",
    "         goog_test.closing_price,\n",
    "         'r',\n",
    "         label=\"Test Data\")\n",
    "\n",
    "## We can get the forecast with .forecast(h)\n",
    "plt.plot(goog_test.date, \n",
    "         exp_smooth.forecast(14),\n",
    "         'r--o',\n",
    "         label=\"Double Exponential Smoothing Prediction\")\n",
    "\n",
    "plt.xlabel(\"Date\", fontsize=18)\n",
    "plt.ylabel(\"Closing Price\", fontsize=18)\n",
    "\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14, loc=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb2a46",
   "metadata": {},
   "source": [
    "<i>Note: The observations may look like not a straight line, but that is because we do not trade stocks on the weekend</i>\n",
    "\n",
    "As we can see from this example, that depending on the value of $\\beta$ double exponential smoothing may pay too much attention to a recent trend. Again you can play around with finding the optimal $\\alpha$ and $\\beta$ with cross-validation or a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5eb4a9",
   "metadata": {},
   "source": [
    "### Triple exponential smoothing or the Holt-Winters forecast\n",
    "\n",
    "The final forecast we will look at in this notebook is <i>triple exponential smoothing</i> or the <i>Holt-Winters</i> model. Holt-Winters adds a third smoothing component to account for seasonal trends in time series. The third component can take one of two forms because there can be different kinds of seasonality present in a time series.\n",
    "\n",
    "#### 1. Multiplicative version\n",
    "\n",
    "The first of these is thought of as <i>multiplicative seasonality</i>. \n",
    "\n",
    "Multiplicative seasonality occurs when the value of the next time step in the cycle is some <i>multiple</i> of the previous time step. For example, in infectious disease spread there is the concept of $R_0$, which is the number of individuals an infectious person is expected to infect in a completely susceptible population. So early in the stages of infectious disease spread, we may reasonably assume that the number of new cases in the next time step is roughly $R_0$ times the number of new cases in this time step (assuming that, again, we are early in the disease spreading process and the time step roughly corresponds with the infectious period of the disease and a lot of other assumptions that infectious disease modelers make).\n",
    "\n",
    "The multiplicative version of the Holt-Winters model is:\n",
    "\n",
    "$$\n",
    "\\hat{y}_{t} = \\left\\lbrace \\begin{array}{l c c} \\left( s_{t-1} + b_{t-1} \\right) c_{t-m} & \\text{for} & 1<t\\leq n \\\\\n",
    "                                                \\left( s_n + (t-n)b_n \\right)c_{n-m+1 + (t-n-1)\\%m} & \\text{for} & t > n \\end{array}\\right\\rbrace, \n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "s_{t+1} = \\alpha \\frac{y_t}{c_{t-m}} + \\left(1-\\alpha\\right) \\left( s_{t-1} + b_{t-1}\\right), \\ s_1 = y_1,\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_{t+1} = \\beta (s_t - s_{t-1}) + (1-\\beta)b_{t-1}, \\ b_1 = y_2 - y_1,\n",
    "$$\n",
    "\n",
    "$$\n",
    "c_{t+1} = \\gamma \\frac{y_t}{s_t} + (1-\\gamma)c_{t-m},\n",
    "$$\n",
    "\n",
    "$\\%$ denotes modular division, $m$ is the number of time steps that make up a season and $\\alpha \\in [0,1]$, $\\beta \\in [0,1]$ and $\\gamma \\in [0,1]$ are all hyperparameters.\n",
    "\n",
    "#### 2. Additive version\n",
    "\n",
    "The second form of seasonality is thought of as <i>additive seasonality</i>.\n",
    "\n",
    "Additive seasonality is when the value at the subsequent time step in the cycle is some amount added to the previous step. For example, maybe an ice cream shop consistently sees $\\$ 100$ more in sales from Q3 to Q4, due to say a typical increase in temperature.\n",
    "\n",
    "The additive Holt-Winters model is:\n",
    "\n",
    "$$\n",
    "\\hat{y}_{t} = \\left\\lbrace \\begin{array}{l c c} s_{t-1} + b_{t-1} + c_{t-m} & \\text{for} & 1<t\\leq n \\\\\n",
    "                                                s_n + (t-n)b_n  + c_{n-m+1 + (t-n-1)\\%m} & \\text{for} & t > n \\end{array}\\right\\rbrace, \n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "s_{t+1} = \\alpha (y_t - c_{t-m}) + \\left(1-\\alpha\\right) \\left( s_{t-1} + b_{t-1}\\right), \\ s_1 = y_1,\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_{t+1} = \\beta (s_t - s_{t-1}) + (1-\\beta)b_{t-1}, \\ b_1 = y_2 - y_1,\n",
    "$$\n",
    "\n",
    "$$\n",
    "c_{t+1} = \\gamma (y_t - s_{t-1} - b_{t-1}) + (1-\\gamma)c_{t-m},\n",
    "$$\n",
    "\n",
    "$\\%$ denotes modular division, $m$ is the number of time steps that make up a season and $\\alpha$, $\\beta$ and $\\gamma$ are all hyperparameters.\n",
    "\n",
    "#### Implementing in python\n",
    "\n",
    "You can implement either version of the Holt-Winters model in python using `statsmodels` `ExponentialSmoothing` model, <a href=\"https://www.statsmodels.org/devel/generated/statsmodels.tsa.holtwinters.ExponentialSmoothing.html\">https://www.statsmodels.org/devel/generated/statsmodels.tsa.holtwinters.ExponentialSmoothing.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f4e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d361a1",
   "metadata": {},
   "source": [
    "To test this model out we will return to our flu data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d17789",
   "metadata": {},
   "outputs": [],
   "source": [
    "flu = pd.read_csv(\"../../../Data/us_flu_1928_1948.csv\", parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed7dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "plt.plot(flu.date, flu.cases)\n",
    "\n",
    "plt.xlabel(\"Date\", fontsize=18)\n",
    "plt.ylabel(\"New Seasonal Influenza Cases\", fontsize=18)\n",
    "\n",
    "plt.xticks([datetime(1928,1,1) + timedelta(days=365*i) for i in range(21)],\n",
    "           [str(i) for i in range(1928, 1949)],\n",
    "           fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e260d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "flu_train = flu.loc[flu.year < 1947].copy()\n",
    "flu_test = flu.loc[flu.year == 1947].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c517aa4",
   "metadata": {},
   "source": [
    "For these data we will use the mutliplicative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e8bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Call ExponentialSmoothing\n",
    "## input the training data\n",
    "## set seasonal = \"mul\", for additive you would set it equal to \"add\"\n",
    "## You set m using seasonal_periods = \n",
    "## Then call fit\n",
    "## set a smoothing_level, alpha\n",
    "## set a smoothing_trend, beta\n",
    "## set a smoothing_seasonal, gamma\n",
    "## Set optimized = False, unless you want maximum likelihood to estimate alpha, beta, gamma\n",
    "holt_winter = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116a94fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(flu_train.date, \n",
    "         flu_train.cases,\n",
    "         'b-',\n",
    "         label=\"Training Data\")\n",
    "plt.plot(flu_train.date, \n",
    "         holt_winter.fittedvalues, \n",
    "         'g-',\n",
    "         label=\"Holt-Winter Fit\")\n",
    "\n",
    "plt.plot(flu_test.date, \n",
    "         flu_test.cases,\n",
    "         'r-',\n",
    "         label=\"Test Data\")\n",
    "\n",
    "plt.plot(flu_test.date, \n",
    "         holt_winter.forecast(52),\n",
    "         'r--',\n",
    "         label=\"Holt-Winters Predictions\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"Date\", fontsize=18)\n",
    "plt.ylabel(\"New Seasonal Influenza Cases\", fontsize=18)\n",
    "\n",
    "plt.xticks([datetime(1928,1,1) + timedelta(days=365*i) for i in range(21)],\n",
    "           [str(i) for i in range(1928, 1949)],\n",
    "           fontsize=14)\n",
    "         \n",
    "plt.yticks(fontsize=14)\n",
    "         \n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fc5e60",
   "metadata": {},
   "source": [
    "As we have said before we can use cross-validation or a validation set to find the \"best\" values for our hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936cecd7",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the ErdÅ‘s Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4897ae2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
