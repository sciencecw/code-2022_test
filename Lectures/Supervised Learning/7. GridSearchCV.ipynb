{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5fae96e",
   "metadata": {},
   "source": [
    "# `GridSearchCV`\n",
    "\n",
    "Let's learn about a quick and easy way to conduct a cross-validation grid search without having to write a `for` loop.\n",
    "\n",
    "## What we will accomplish\n",
    "\n",
    "In this notebook we will:\n",
    "- Work on a synthetic regression example,\n",
    "- Refresh ourselves on hyperparameter tuning using cross-validation,\n",
    "- Demonstrate what we would do using `KFold` and a `for` loop and\n",
    "- Compare that to what we would do using `GridSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d893d9b",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "\n",
    "Over the course of our supervised learning content we talked a lot about choosing the \"best\" hyperparameter values (think $\\alpha$ in Ridge/Lasso regression, or $k$ in $k$NN) using cross-validation. What this entails is fitting the model with each potential set of hyperparameter values on each cross-validation split and then recording the performance on the holdout set.\n",
    "\n",
    "Typically you <i>tune</i> hyperparameters, i.e. find the \"best\" values, by setting up grids for your potential hyperparameter values. For example, in a $k$NN setting you would set up a grid that starts at your minimum number of neighbors (like $k=1$) and incrementally increases to your maximum number of neighbors (like $k=50$).\n",
    "\n",
    "### A synthetic regression example\n",
    "\n",
    "Let's do just that with this synthetic data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64c29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(403940)\n",
    "X_train = np.random.randn(500,2)\n",
    "X_train[:,0] = 1.3*X_train[:,0] - 2\n",
    "X_train[:,1] = .8*X_train[:,1] + 1.2\n",
    "\n",
    "y_train = X_train[:,0] + 2.3*X_train[:,1] - 2 + np.random.randn(500)*1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446d975f",
   "metadata": {},
   "source": [
    "We will fit a $k$NN regression model, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\">https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html</a>, on these data. In particular we will use a `for` loop and `KFold` to find the optimal values for `n_neighbors` and `weights`, where optimal indicates the pair with lowest average cross-validation mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589cdee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6d58a",
   "metadata": {},
   "source": [
    "For `n_neighbors` we will go from `1` to `50` and for `weights` we will examine `'uniform'` and `'distance'`, the two arguments allowed by `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576ea3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = range(1,51)\n",
    "weights = ['uniform', 'distance']\n",
    "\n",
    "## this array will track performance across all splits, n_neighbors, and weights\n",
    "cv_mses = np.zeros((5, len(n_neighbors), len(weights)))\n",
    "\n",
    "kfold = KFold(5, shuffle=True, random_state = 30293)\n",
    "\n",
    "## keeps track of cv_split\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_train, y_train):\n",
    "    X_tt = X_train[train_index, :]\n",
    "    y_tt = y_train[train_index]\n",
    "    X_ho = X_train[test_index, :]\n",
    "    y_ho = y_train[test_index]\n",
    "    \n",
    "    ## keeps track of neighbor split\n",
    "    j = 0\n",
    "    for neighbors in n_neighbors:\n",
    "        ## keeps track of weight split\n",
    "        k = 0\n",
    "        for weighting in weights:\n",
    "            ## make the model object\n",
    "            knn = KNeighborsRegressor(n_neighbors = neighbors,\n",
    "                                         weights = weighting)\n",
    "            \n",
    "            ## fit the model\n",
    "            knn.fit(X_tt, y_tt)\n",
    "            \n",
    "            ## get the prediction\n",
    "            pred = knn.predict(X_ho)\n",
    "            \n",
    "            ## store the mse\n",
    "            cv_mses[i,j,k] = mean_squared_error(y_ho, pred)\n",
    "            \n",
    "            k = k + 1\n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8681d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cv_mses, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will get you the index where the minimum occurs\n",
    "np.unravel_index(np.mean(cv_mses, axis=0).argmin(), np.mean(cv_mses, axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d3afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the min avg cv\n",
    "np.mean(cv_mses, axis=0)[7,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485881f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this was the number of neighbors that got us there\n",
    "n_neighbors[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bea79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this was the weighting\n",
    "weights[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313eb916",
   "metadata": {},
   "source": [
    "Now this example involed a two dimensional grid search, which was not too difficult to write up, but what if we wanted to test a random forest model which can involve tuning way more than two hyperparameters.\n",
    "\n",
    "At a certain point, explicitly writing a `for` loop becomes tedious.\n",
    "\n",
    "Luckily, `sklearn` provides a model selection object called `GridSearchCV`, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html</a>, which will implement the grid search hyperparameter tuning for you.\n",
    "\n",
    "Let's demonstrate how now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e2344",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import GridSearchCV\n",
    "from sklearn.model_selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e84a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## when defining a GridSearchCV object you first\n",
    "## place in an empty model object,\n",
    "## Then a dictionary containing the grids for each of the parameters you\n",
    "## want to test into param_grid,\n",
    "## Then a string with how you want to \"score\" the model in scoring,\n",
    "## Then how many splits you want to use in cv, the default is 5\n",
    "grid_cv = \n",
    "\n",
    "\n",
    "## Then you call to fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff4d6b4",
   "metadata": {},
   "source": [
    "When you call `.fit` the `GridSearchCV` object goes through the same `for` loop procedure we manually coded above and finds the `scoring` value for each of the grid points you have fed into the object.\n",
    "\n",
    "When it is done we can access the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can find the hyperparameter grid point that\n",
    "## gave the best performance like so\n",
    "## .best_params_\n",
    "grid_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4f3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can find the best score like so\n",
    "## .best_score_\n",
    "grid_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96011562",
   "metadata": {},
   "outputs": [],
   "source": [
    "## You can get all of the results with cv_results_\n",
    "grid_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4de30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calling best_estimator_ returns the model with the \n",
    "## best avg cv performance after it has been refit on the\n",
    "## entire data set\n",
    "grid_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac735b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6945d1",
   "metadata": {},
   "source": [
    "Before we end this notebook you may have a couple of questions.\n",
    "\n",
    "First you may have noticed that our score was `'neg_mean_squared_error'` instead of `'mean_square_error'`. This is because the `GridSearchCV` does not offer mean squared error as an option.\n",
    "\n",
    "To see what metrics are available as scoring options we can run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91f3e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import SCORERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7a558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORERS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0e5725",
   "metadata": {},
   "source": [
    "Another thing you may notice is that the model chosen by the `GridSearchCV` is not the same as the model we found with our handwritten `for` loop.\n",
    "\n",
    "If you compare the performance, their avg cv scores are close, indicating that this is likely due to `GridSearchCV` using a different cross-validation split than ours. We can rectify that like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e437db",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv = GridSearchCV(KNeighborsRegressor(), \n",
    "                         param_grid = {'n_neighbors':range(1,50),\n",
    "                                          'weights':['uniform', 'distance']}, \n",
    "                         scoring = 'neg_mean_squared_error',\n",
    "                         cv = )\n",
    "\n",
    "grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d2d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7923f98c",
   "metadata": {},
   "source": [
    "You now have a good base understanding of `GridSearchCV`. If you would like to learn more you can experiment on your own, or read the documentation, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\">https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70148c7",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2022.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erdős Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23823942",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
